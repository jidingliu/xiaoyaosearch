"""
Unit tests for full-text search components.

This module tests all full-text search functionality including Whoosh integration,
index operations, and search management.
"""

import pytest
import tempfile
import shutil
import json
from pathlib import Path
from datetime import datetime, timedelta
from unittest.mock import patch, MagicMock

# Test the full-text search components
from services.fulltext.fulltext_index import FullTextIndex
from services.fulltext.fulltext_manager import FullTextSearchManager


# Skip tests if Whoosh is not available
whoosh = pytest.importorskip("whoosh")


@pytest.fixture
def temp_dir():
    """Create a temporary directory for test files."""
    temp_path = tempfile.mkdtemp()
    yield temp_path
    # Windows-safe cleanup
    import time
    for _ in range(3):
        try:
            shutil.rmtree(temp_path)
            return
        except PermissionError:
            time.sleep(0.1)
        except Exception:
            return


@pytest.fixture
def sample_documents():
    """Create sample documents for testing."""
    return [
        {
            'doc_id': 1,
            'title': 'artificial intelligence report',
            'content': 'artificial intelligence is a branch of computer science that aims to understand the essence of intelligence.',
            'filename': 'ai_report.txt',
            'file_path': '/documents/ai_report.txt',
            'extension': 'txt',
            'content_type': 'text',
            'file_size': 1024,
            'created_at': datetime(2024, 1, 1),
            'modified_at': datetime(2024, 1, 15),
            'tags': ['ai', 'technology', 'report'],
            'language': 'en',
            'file_id': 1
        },
        {
            'doc_id': 2,
            'title': 'machine learning tutorial',
            'content': 'machine learning is the core of artificial intelligence and the fundamental way to make computers intelligent.',
            'filename': 'ml_tutorial.pdf',
            'file_path': '/documents/ml_tutorial.pdf',
            'extension': 'pdf',
            'content_type': 'pdf',
            'file_size': 2048,
            'created_at': datetime(2024, 2, 1),
            'modified_at': datetime(2024, 2, 15),
            'tags': ['machine learning', 'tutorial', 'ai'],
            'language': 'en',
            'file_id': 2
        },
        {
            'doc_id': 3,
            'title': 'Deep Learning with Python',
            'content': 'Deep learning with Python is a subset of machine learning that uses multi-layered neural networks. Python programming language provides excellent libraries like TensorFlow and PyTorch for implementing neural networks.',
            'filename': 'deep_learning_python.py',
            'file_path': '/code/deep_learning_python.py',
            'extension': 'py',
            'content_type': 'code',
            'file_size': 512,
            'created_at': datetime(2024, 3, 1),
            'modified_at': datetime(2024, 3, 10),
            'tags': ['deep learning', 'python', 'neural networks'],
            'language': 'en',
            'file_id': 3
        }
    ]


@pytest.fixture
def fulltext_index(temp_dir):
    """Create a FullTextIndex instance for testing."""
    index_dir = Path(temp_dir) / "test_index"
    return FullTextIndex(index_dir=str(index_dir))


@pytest.fixture
def fulltext_manager(temp_dir):
    """Create a FullTextSearchManager instance for testing."""
    index_dir = Path(temp_dir) / "test_manager_index"
    return FullTextSearchManager(index_dir=str(index_dir))


class TestFullTextIndex:
    """Test the FullTextIndex class."""

    def test_fulltext_index_initialization(self, temp_dir):
        """Test FullTextIndex initialization."""
        index_dir = Path(temp_dir) / "test_init"
        ft_index = FullTextIndex(index_dir=str(index_dir))

        assert ft_index.index_dir == index_dir
        assert ft_index.index is not None
        assert ft_index.schema is not None
        assert index_dir.exists()

    def test_fulltext_index_custom_schema(self, temp_dir):
        """Test FullTextIndex with custom schema."""
        index_dir = Path(temp_dir) / "test_custom"
        custom_fields = {
            'custom_field': whoosh.fields.TEXT(stored=True)
        }
        ft_index = FullTextIndex(index_dir=str(index_dir), schema_fields=custom_fields)

        assert 'custom_field' in ft_index.schema
        assert ft_index.schema['custom_field'].stored is True

    def test_add_document(self, fulltext_index, sample_documents):
        """Test adding a document to the index."""
        doc = sample_documents[0]

        result = fulltext_index.add_document(**doc)
        assert result is True

        # Verify document was added by searching for it
        results = fulltext_index.search("artificial")
        assert len(results) >= 1
        assert any(result['doc_id'] == doc['doc_id'] for result in results)

    def test_add_multiple_documents(self, fulltext_index, sample_documents):
        """Test adding multiple documents."""
        for doc in sample_documents:
            result = fulltext_index.add_document(**doc)
            assert result is True

        # Search for different terms
        ai_results = fulltext_index.search("intelligence")
        ml_results = fulltext_index.search("machine")
        dl_results = fulltext_index.search("Deep")

        assert len(ai_results) >= 1
        assert len(ml_results) >= 1
        assert len(dl_results) >= 1

    def test_search_basic(self, fulltext_index, sample_documents):
        """Test basic search functionality."""
        # Add documents first
        for doc in sample_documents:
            fulltext_index.add_document(**doc)

        # Search for specific terms
        results = fulltext_index.search("intelligence")
        assert len(results) >= 1
        assert all('intelligence' in result['title'].lower() or 'intelligence' in result['content'].lower() for result in results)

    def test_search_with_fields(self, fulltext_index, sample_documents):
        """Test search with specific fields."""
        for doc in sample_documents:
            fulltext_index.add_document(**doc)

        # Search only in title field
        results = fulltext_index.search("machine", fields=['title'])
        assert len(results) >= 1

        # Search only in content field
        results = fulltext_index.search("Python", fields=['content'])
        assert len(results) >= 1

    def test_search_with_limits(self, fulltext_index, sample_documents):
        """Test search with result limits and offsets."""
        for doc in sample_documents:
            fulltext_index.add_document(**doc)

        # Test limit
        results = fulltext_index.search("intelligence", limit=1)
        assert len(results) <= 1

        # Test offset
        all_results = fulltext_index.search("intelligence", limit=10)
        if len(all_results) > 1:
            offset_results = fulltext_index.search("intelligence", limit=1, offset=1)
            assert len(offset_results) <= 1

    def test_search_with_filters(self, fulltext_index, sample_documents):
        """Test search with filters."""
        for doc in sample_documents:
            fulltext_index.add_document(**doc)

        # Filter by content type
        results = fulltext_index.search("technology", filters={'content_type': 'text'})
        assert all(result['content_type'] == 'text' for result in results)

        # Filter by extension
        results = fulltext_index.search("learning", filters={'extension': 'pdf'})
        assert all(result['extension'] == 'pdf' for result in results)

    def test_search_phrase_search(self, fulltext_index, sample_documents):
        """Test phrase search functionality."""
        for doc in sample_documents:
            fulltext_index.add_document(**doc)

        # Enable phrase search
        results = fulltext_index.search("machine learning", phrase_search=True)
        # This should find documents containing the exact phrase
        assert len(results) >= 0

    def test_search_empty_query(self, fulltext_index):
        """Test search with empty query."""
        results = fulltext_index.search("")
        assert results == []

        results = fulltext_index.search("   ")
        assert results == []

    def test_update_document(self, fulltext_index, sample_documents):
        """Test updating a document."""
        doc = sample_documents[0]
        fulltext_index.add_document(**doc)

        # Update document
        updated_data = {
            'title': doc['title'],
            'content': 'æ›´æ–°åŽçš„å†…å®¹ï¼šæ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ã€‚',
            'filename': doc['filename'],
            'file_path': doc['file_path'],
            'extension': doc['extension'],
            'content_type': doc['content_type'],
            'file_size': doc['file_size'],
            'created_at': doc['created_at'],
            'modified_at': doc['modified_at'],
            'tags': doc['tags'],
            'language': doc['language']
        }

        result = fulltext_index.update_document(doc['doc_id'], **updated_data)
        assert result is True

        # Verify update
        results = fulltext_index.search("æ›´æ–°åŽçš„å†…å®¹")
        assert len(results) == 1
        assert results[0]['doc_id'] == doc['doc_id']

    def test_delete_document(self, fulltext_index, sample_documents):
        """Test deleting a document."""
        doc = sample_documents[0]
        fulltext_index.add_document(**doc)

        # Verify document exists
        results = fulltext_index.search("artificial")
        assert len(results) >= 1

        # Delete document
        result = fulltext_index.delete_document(doc['doc_id'])
        assert result is True

        # Verify document is deleted
        results = fulltext_index.search("artificial")
        assert len(results) == 0

    def test_delete_documents_by_field(self, fulltext_index, sample_documents):
        """Test deleting documents by field value."""
        for doc in sample_documents:
            fulltext_index.add_document(**doc)

        # Delete all documents with specific content type
        result = fulltext_index.delete_documents_by_field('content_type', 'text')
        assert result is True

        # Verify deletion
        results = fulltext_index.search("*", use_bm25=False)
        for result in results:
            assert result['content_type'] != 'text'

    def test_suggest_terms(self, fulltext_index, sample_documents):
        """Test term suggestions for autocomplete."""
        for doc in sample_documents:
            fulltext_index.add_document(**doc)

        # Get suggestions for a prefix
        suggestions = fulltext_index.suggest_terms("artificial", field='title')
        assert isinstance(suggestions, list)
        # Should find terms starting with "artificial"
        assert any("artificial" in term.lower() for term in suggestions)

    def test_get_index_stats(self, fulltext_index, sample_documents):
        """Test getting index statistics."""
        # Empty index stats
        stats = fulltext_index.get_index_stats()
        assert 'doc_count' in stats
        assert 'field_names' in stats
        assert stats['doc_count'] == 0

        # Add documents and get stats
        for doc in sample_documents:
            fulltext_index.add_document(**doc)

        stats = fulltext_index.get_index_stats()
        assert stats['doc_count'] == len(sample_documents)
        assert isinstance(stats['field_names'], list)
        assert 'title' in stats['field_names']
        assert 'content' in stats['field_names']

    def test_optimize_index(self, fulltext_index, sample_documents):
        """Test index optimization."""
        # Add documents
        for doc in sample_documents:
            fulltext_index.add_document(**doc)

        # Optimize index
        result = fulltext_index.optimize_index()
        assert result is True

        # Verify index still works after optimization
        results = fulltext_index.search("artificial")
        assert len(results) >= 1

    def test_rebuild_index(self, fulltext_index, sample_documents):
        """Test rebuilding the entire index."""
        # Add some documents
        fulltext_index.add_document(**sample_documents[0])

        # Rebuild index with new documents (need to convert doc_id to id)
        rebuild_docs = []
        for doc in sample_documents[1:]:
            rebuild_doc = doc.copy()
            rebuild_doc['id'] = rebuild_doc.pop('doc_id')  # Convert doc_id to id
            rebuild_docs.append(rebuild_doc)

        result = fulltext_index.rebuild_index(rebuild_docs)
        assert result is True

        # Verify new documents exist (check if any documents were indexed)
        results = fulltext_index.search("intelligence", use_bm25=False)
        assert len(results) >= len(sample_documents) - 2  # Allow for indexing differences

    def test_clear_index(self, fulltext_index, sample_documents):
        """Test clearing the index."""
        # Add documents
        for doc in sample_documents:
            fulltext_index.add_document(**doc)

        # Clear index
        result = fulltext_index.clear_index()
        assert result is True

        # Verify index is empty
        stats = fulltext_index.get_index_stats()
        assert stats['doc_count'] == 0

    def test_search_result_formatting(self, fulltext_index, sample_documents):
        """Test that search results are properly formatted."""
        doc = sample_documents[0]
        fulltext_index.add_document(**doc)

        results = fulltext_index.search("artificial")
        assert len(results) == 1

        result = results[0]
        # Check required fields
        assert 'score' in result
        assert 'doc_id' in result
        assert 'rank' in result
        assert 'title' in result
        assert 'content' in result
        assert 'filename' in result
        assert 'file_path' in result

        # Check values
        assert result['doc_id'] == doc['doc_id']
        assert result['title'] == doc['title']
        assert isinstance(result['score'], float)
        assert result['rank'] >= 1

    def test_tags_handling(self, fulltext_index):
        """Test tags field handling."""
        doc_with_tags = {
            'doc_id': 1,
            'title': 'Test Document',
            'content': 'Test content with tags',
            'filename': 'test.txt',
            'file_path': '/test.txt',
            'extension': 'txt',
            'content_type': 'text',
            'file_size': 100,
            'created_at': datetime.now(),
            'modified_at': datetime.now(),
            'tags': ['tag1', 'tag2', 'tag3'],
            'language': 'zh'
        }

        fulltext_index.add_document(**doc_with_tags)
        results = fulltext_index.search("Test", use_bm25=False)
        assert len(results) == 1

        result = results[0]
        assert isinstance(result['tags'], list)
        assert set(result['tags']) == {'tag1', 'tag2', 'tag3'}

    def test_error_handling_in_add_document(self, fulltext_index):
        """Test error handling when adding document."""
        # Try to add document with invalid data
        invalid_doc = {
            'doc_id': 'invalid_id',  # Should be int
            'title': 'Invalid Document',
            'content': 'Invalid content',
            'filename': 'invalid.txt',
            'file_path': '/invalid.txt',
            'extension': 'txt',
            'content_type': 'text',
            'file_size': 'invalid_size',  # Should be int
            'created_at': 'invalid_date',  # Should be datetime
            'modified_at': 'invalid_date',
            'language': 'zh'
        }

        # Should handle error gracefully
        try:
            result = fulltext_index.add_document(**invalid_doc)
            # The result depends on the implementation, but it shouldn't crash
            assert isinstance(result, bool)
        except Exception as e:
            # Should handle the error without crashing
            assert True  # If we get here, error handling is working

        # Explicitly close any open index files to prevent Windows file locking
        try:
            if hasattr(fulltext_index, 'index') and fulltext_index.index:
                # Force the index to close properly
                del fulltext_index.index
        except:
            pass

    def test_index_persistence(self, temp_dir, sample_documents):
        """Test that index persists across instances."""
        index_dir = Path(temp_dir) / "persistent_index"

        # Create index and add documents
        ft_index1 = FullTextIndex(index_dir=str(index_dir))
        ft_index1.add_document(**sample_documents[0])
        ft_index1.add_document(**sample_documents[1])

        # Create new instance - should load existing index
        ft_index2 = FullTextIndex(index_dir=str(index_dir))

        # Verify documents are still there
        results = ft_index2.search("artificial")
        assert len(results) >= 1

    def test_chinese_analyzer(self, fulltext_index):
        """Test text analysis with standard analyzer."""
        # Test with simple English content to verify analyzer works
        test_doc = {
            'doc_id': 1,
            'title': 'Text Analysis Test',
            'content': 'This is a test for text analysis and search functionality. We need to verify that the analyzer processes text correctly.',
            'filename': 'analysis_test.txt',
            'file_path': '/analysis_test.txt',
            'extension': 'txt',
            'content_type': 'text',
            'file_size': 100,
            'created_at': datetime.now(),
            'modified_at': datetime.now(),
            'language': 'en'
        }

        fulltext_index.add_document(**test_doc)

        # Test word search
        results = fulltext_index.search("text")
        assert len(results) == 1

        results = fulltext_index.search("analysis")
        assert len(results) == 1

        results = fulltext_index.search("test")
        assert len(results) == 1

    def test_mixed_language_search(self, fulltext_index, sample_documents):
        """Test searching with mixed Chinese and English content."""
        for doc in sample_documents:
            fulltext_index.add_document(**doc)

        # Chinese search
        chinese_results = fulltext_index.search("artificial")
        assert len(chinese_results) >= 1

        # English search
        english_results = fulltext_index.search("Python")
        assert len(english_results) >= 1


class TestFullTextSearchManager:
    """Test the FullTextSearchManager class."""

    def test_manager_initialization(self, temp_dir):
        """Test FullTextSearchManager initialization."""
        index_dir = Path(temp_dir) / "test_manager"
        manager = FullTextSearchManager(index_dir=str(index_dir))

        assert manager.fulltext_index is not None
        assert index_dir.exists()

    def test_index_file_content(self, fulltext_manager):
        """Test indexing file content."""
        result = fulltext_manager.index_file_content(
            file_id=1,
            content="This is a test document content for verifying file content indexing functionality.",
            title="Test Document",
            filename="test.txt",
            file_path="/documents/test.txt",
            extension="txt",
            content_type="text",
            file_size=100,
            tags=["test", "document"]
        )

        assert result is True

        # Verify content was indexed
        results = fulltext_manager.search_files("test")
        assert len(results) >= 1

    def test_index_content_chunks(self, fulltext_manager):
        """Test indexing content chunks."""
        chunks = [
            {"content": "This is the first chunk content.", "title": "First chunk"},
            {"content": "This is the second chunk content.", "title": "Second chunk"},
            {"content": "This is the third chunk content.", "title": "Third chunk"}
        ]

        metadata = {
            'filename': 'chunked_document.txt',
            'file_path': '/documents/chunked_document.txt',
            'extension': 'txt',
            'content_type': 'text',
            'tags': ['åˆ†å—', 'æµ‹è¯•']
        }

        successful = fulltext_manager.index_content_chunks(
            file_id=2,
            chunks=chunks,
            metadata=metadata
        )

        assert successful == len(chunks)

        # Verify chunks were indexed
        results = fulltext_manager.search_files("chunk")
        assert len(results) >= 1

    def test_search_files_basic(self, fulltext_manager):
        """Test basic file search."""
        # Index some test files
        fulltext_manager.index_file_content(
            file_id=1,
            content="artificial intelligence and machine learning are popular technology fields.",
            title="AI Technology Report",
            filename="ai_report.txt",
            extension="txt",
            content_type="text"
        )

        fulltext_manager.index_file_content(
            file_id=2,
            content="Python is the most popular programming language in machine learning field.",
            title="Python Programming Guide",
            filename="python_guide.pdf",
            extension="pdf",
            content_type="pdf"
        )

        # Search for AI-related content
        results = fulltext_manager.search_files("artificial")
        assert len(results) >= 1

        # Search for Python content
        results = fulltext_manager.search_files("Python")
        assert len(results) >= 1

    def test_search_files_with_filters(self, fulltext_manager):
        """Test file search with filters."""
        # Index test files with different types
        fulltext_manager.index_file_content(
            file_id=1,
            content="Text document content",
            title="Text Document",
            filename="doc.txt",
            extension="txt",
            content_type="text",
            tags=["text", "document"]
        )

        fulltext_manager.index_file_content(
            file_id=2,
            content="PDF document content",
            title="PDF Document",
            filename="doc.pdf",
            extension="pdf",
            content_type="pdf",
            tags=["pdf", "document"]
        )

        # Filter by content type
        results = fulltext_manager.search_files("document", content_type="text")
        assert all(result['content_type'] == 'text' for result in results)

        # Filter by extension
        results = fulltext_manager.search_files("document", extension=["pdf"])
        assert all(result['extension'] == 'pdf' for result in results)

        # Filter by tags
        results = fulltext_manager.search_files("document", tags=["text"])
        assert all('text' in result['tags'] for result in results)

    def test_search_within_file(self, fulltext_manager):
        """Test searching within a specific file."""
        # Index a file with multiple chunks
        chunks = [
            {"content": "This is an introduction to machine learning."},
            {"content": "Deep learning is an important branch of machine learning."},
            {"content": "Neural networks are the foundation of deep learning."}
        ]

        fulltext_manager.index_content_chunks(
            file_id=1,
            chunks=chunks
        )

        # Search within the file
        results = fulltext_manager.search_within_file(
            file_id=1,
            query="learning"
        )

        assert len(results) >= 1
        assert all(result['file_id'] == 1 for result in results)

    def test_get_file_chunks(self, fulltext_manager):
        """Test getting all chunks for a file."""
        chunks = [
            {"content": "ç¬¬ä¸€æ®µå†…å®¹"},
            {"content": "ç¬¬äºŒæ®µå†…å®¹"},
            {"content": "ç¬¬ä¸‰æ®µå†…å®¹"}
        ]

        fulltext_manager.index_content_chunks(file_id=1, chunks=chunks)

        # Get all chunks
        file_chunks = fulltext_manager.get_file_chunks(file_id=1)
        assert len(file_chunks) == len(chunks)

        # Verify chunks are sorted by chunk_index
        chunk_indices = [chunk.get('chunk_index', 0) for chunk in file_chunks]
        assert chunk_indices == sorted(chunk_indices)

    def test_delete_file_from_index(self, fulltext_manager):
        """Test deleting a file from the index."""
        # Index a file
        fulltext_manager.index_file_content(
            file_id=1,
            content="Test file content",
            title="Test File",
            filename="test.txt"
        )

        # Verify file exists
        results = fulltext_manager.search_files("Test")
        assert len(results) >= 1

        # Delete file
        result = fulltext_manager.delete_file_from_index(file_id=1)
        assert result is True

        # Verify file is deleted
        results = fulltext_manager.search_files("Test")
        assert len(results) == 0

    def test_update_file_access_count(self, fulltext_manager):
        """Test updating file access count."""
        # Index a file with chunks
        chunks = [
            {"content": "Chunk 1 content"},
            {"content": "Chunk 2 content"}
        ]

        fulltext_manager.index_content_chunks(file_id=1, chunks=chunks)

        # Update access count
        result = fulltext_manager.update_file_access_count(file_id=1, increment=5)
        assert result is True

        # Verify access count was updated
        file_chunks = fulltext_manager.get_file_chunks(file_id=1)
        for chunk in file_chunks:
            assert chunk.get('access_count', 0) >= 5

    def test_suggest_search_terms(self, fulltext_manager):
        """Test getting search term suggestions."""
        # Index content with various terms
        fulltext_manager.index_file_content(
            file_id=1,
            content="artificial intelligence, machine learning, deep learning, neural networks",
            title="AIæœ¯è¯­",
            filename="ai_terms.txt"
        )

        # Get suggestions
        suggestions = fulltext_manager.suggest_search_terms("äººå·¥")
        assert isinstance(suggestions, list)
        assert len(suggestions) >= 0

    def test_get_search_statistics(self, fulltext_manager):
        """Test getting comprehensive search statistics."""
        # Index various types of files
        fulltext_manager.index_file_content(
            file_id=1,
            content="Text content",
            title="Text File",
            filename="doc.txt",
            extension="txt",
            content_type="text"
        )

        fulltext_manager.index_file_content(
            file_id=2,
            content="PDF content",
            title="PDF File",
            filename="doc.pdf",
            extension="pdf",
            content_type="pdf"
        )

        # Get statistics
        stats = fulltext_manager.get_search_statistics()
        assert 'doc_count' in stats
        assert 'field_names' in stats
        assert stats['doc_count'] >= 2

    def test_optimize_index(self, fulltext_manager):
        """Test index optimization."""
        # Index some content
        fulltext_manager.index_file_content(
            file_id=1,
            content="Test content for optimization",
            title="Test Optimization",
            filename="test.txt"
        )

        # Optimize index
        result = fulltext_manager.optimize_index()
        assert result is True

        # Verify search still works after optimization
        results = fulltext_manager.search_files("Test")
        assert len(results) >= 1

    def test_rebuild_index_from_metadata(self, fulltext_manager):
        """Test rebuilding index from metadata."""
        # Prepare file metadata
        files_metadata = [
            {
                'id': 1,
                'title': 'Document 1',
                'filename': 'doc1.txt',
                'path': '/documents/doc1.txt',
                'content_text': 'First document content',
                'extension': 'txt',
                'content_type': 'text',
                'size': 100,
                'tags': ['doc1']
            },
            {
                'id': 2,
                'title': 'Document 2',
                'filename': 'doc2.txt',
                'path': '/documents/doc2.txt',
                'content_text': 'Second document content',
                'extension': 'txt',
                'content_type': 'text',
                'size': 200,
                'tags': ['doc2']
            }
        ]

        # Rebuild index
        result = fulltext_manager.rebuild_index_from_metadata(files_metadata)
        assert result is True

        # Verify rebuilt index
        results = fulltext_manager.search_files("document")
        assert len(results) >= 1

    def test_save_index(self, fulltext_manager):
        """Test saving the index."""
        # Index some content
        fulltext_manager.index_file_content(
            file_id=1,
            content="Test save functionality",
            title="Save Test",
            filename="save_test.txt"
        )

        # Save index
        result = fulltext_manager.save_index()
        assert result is True

    def test_error_handling_in_indexing(self, fulltext_manager):
        """Test error handling during indexing operations."""
        # Try to index with invalid data
        result = fulltext_manager.index_file_content(
            file_id=None,  # Invalid file_id
            content=None,  # Invalid content
            title=None     # Invalid title
        )

        # Should handle error gracefully
        assert isinstance(result, bool)

    def test_search_with_special_characters(self, fulltext_manager):
        """Test searching with special characters and symbols."""
        # Index content with special characters
        content = "This document contains special characters: @#$%^&*()_+-={}[]|\\:;\"'<>?,./ and ä¸­æ–‡æ±‰å­—"
        fulltext_manager.index_file_content(
            file_id=1,
            content=content,
            title="Special Characters Test",
            filename="special.txt"
        )

        # Search for parts of the content
        results = fulltext_manager.search_files("special")
        assert len(results) >= 1

        results = fulltext_manager.search_files("ä¸­æ–‡æ±‰å­—")
        assert len(results) >= 1

    def test_large_content_handling(self, fulltext_manager):
        """Test handling of large content documents."""
        # Create large content
        large_content = "This is a very long document content. " * 1000  # Repeat to create large content

        result = fulltext_manager.index_file_content(
            file_id=1,
            content=large_content,
            title="Large Document",
            filename="large.txt",
            file_size=len(large_content.encode('utf-8'))
        )

        assert result is True

        # Search in the large content
        results = fulltext_manager.search_files("long document")
        assert len(results) >= 1

    def test_concurrent_operations(self, fulltext_manager):
        """Test concurrent search and indexing operations."""
        # Index initial content
        fulltext_manager.index_file_content(
            file_id=1,
            content="Initial content",
            title="Initial Document",
            filename="initial.txt"
        )

        # Perform multiple search operations
        results1 = fulltext_manager.search_files("Initial")
        results2 = fulltext_manager.search_files("content")
        results3 = fulltext_manager.search_files("Document")

        # All should find the document
        assert len(results1) >= 1
        assert len(results2) >= 1
        assert len(results3) >= 1

    def test_unicode_content(self, fulltext_manager):
        """Test handling of Unicode content."""
        unicode_content = "ðŸ¤– AI Emoji Test ðŸ§  æµ‹è¯•ä¸­æ–‡ ðŸŒ International content"

        result = fulltext_manager.index_file_content(
            file_id=1,
            content=unicode_content,
            title="Unicode Test ðŸš€",
            filename="unicode.txt"
        )

        assert result is True

        # Search for unicode content
        results = fulltext_manager.search_files("Emoji")
        assert len(results) >= 1


class TestFullTextIntegration:
    """Integration tests for full-text search functionality."""

    def test_end_to_end_workflow(self, fulltext_manager):
        """Test complete end-to-end workflow."""
        # Step 1: Index multiple files
        files_data = [
            {
                'file_id': 1,
                'content': 'artificial intelligence technology applications in medical diagnosis',
                'title': 'AIåŒ»ç–—åº”ç”¨',
                'filename': 'ai_medical.txt',
                'extension': 'txt',
                'content_type': 'text',
                'tags': ['AI', 'åŒ»ç–—', 'è¯Šæ–­']
            },
            {
                'file_id': 2,
                'content': 'Machine Learning algorithms for data analysis',
                'title': 'ML Algorithms',
                'filename': 'ml_algorithms.pdf',
                'extension': 'pdf',
                'content_type': 'pdf',
                'tags': ['ML', 'algorithms', 'data']
            }
        ]

        for file_data in files_data:
            result = fulltext_manager.index_file_content(**file_data)
            assert result is True

        # Step 2: Search across all indexed content
        ai_results = fulltext_manager.search_files("artificial")
        ml_results = fulltext_manager.search_files("Machine Learning")

        assert len(ai_results) >= 1
        assert len(ml_results) >= 1

        # Step 3: Apply filters
        text_results = fulltext_manager.search_files("application", content_type="text")
        pdf_results = fulltext_manager.search_files("algorithms", content_type="pdf")

        # Step 4: Get statistics
        stats = fulltext_manager.get_search_statistics()
        assert stats['doc_count'] >= 2

        # Step 5: Clean up
        for file_data in files_data:
            result = fulltext_manager.delete_file_from_index(file_data['file_id'])
            assert result is True

        # Verify cleanup
        final_stats = fulltext_manager.get_search_statistics()
        assert final_stats['doc_count'] == 0

    def test_performance_with_large_dataset(self, fulltext_manager):
        """Test performance with a larger dataset."""
        # Index a moderate number of documents
        num_docs = 50
        for i in range(num_docs):
            content = f"Document {i} content about various topics including technology, science, and mathematics."
            fulltext_manager.index_file_content(
                file_id=i,
                content=content,
                title=f"Document {i}",
                filename=f"doc_{i}.txt"
            )

        # Test search performance
        import time
        start_time = time.time()

        results = fulltext_manager.search_files("technology", limit=20)

        search_time = time.time() - start_time

        # Should return some results quickly (under 1 second for this dataset)
        assert len(results) >= 1
        assert search_time < 2.0  # 2 second limit for test dataset

        # Get statistics to verify all documents were indexed
        stats = fulltext_manager.get_search_statistics()
        assert stats['doc_count'] >= num_docs

    def test_error_recovery_and_boundary_conditions(self, fulltext_manager):
        """Test error recovery and boundary conditions."""
        # Test with empty content
        result = fulltext_manager.index_file_content(
            file_id=1,
            content="",
            title="Empty Content",
            filename="empty.txt"
        )
        assert isinstance(result, bool)

        # Test with very long title
        long_title = "A" * 1000
        result = fulltext_manager.index_file_content(
            file_id=2,
            content="Content with very long title",
            title=long_title,
            filename="long_title.txt"
        )
        assert isinstance(result, bool)

        # Test with special query patterns
        if result:  # Only test if indexing succeeded
            results = fulltext_manager.search_files("*", use_bm25=False)
            assert isinstance(results, list)

            results = fulltext_manager.search_files("", use_bm25=False)
            assert results == []