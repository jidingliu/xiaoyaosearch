"""
ç´¢å¼•ç®¡ç†APIè·¯ç”±
æä¾›æ–‡ä»¶ç´¢å¼•ç®¡ç†ç›¸å…³çš„APIæ¥å£
"""
import os
import asyncio
from typing import List, Optional, Dict, Any
from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from sqlalchemy.orm import Session

from app.core.database import get_db
from app.core.logging_config import get_logger
from app.core.exceptions import ResourceNotFoundException, ValidationException
from app.core.config import get_settings
from app.schemas.requests import IndexCreateRequest, IndexUpdateRequest
from app.schemas.responses import (
    IndexJobInfo, IndexCreateResponse, IndexListResponse, SuccessResponse
)
from app.schemas.enums import JobType, JobStatus
from app.models.index_job import IndexJobModel
from app.utils.enum_helpers import get_enum_value
from app.models.file import FileModel
from app.services.file_index_service import FileIndexService, get_file_index_service as get_global_file_index_service

router = APIRouter(prefix="/api/index", tags=["ç´¢å¼•ç®¡ç†"])
logger = get_logger(__name__)
settings = get_settings()

# å…¨å±€æ–‡ä»¶ç´¢å¼•æœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹ï¼‰
_file_index_service: Optional[FileIndexService] = None


def get_file_index_service() -> FileIndexService:
    """è·å–æ–‡ä»¶ç´¢å¼•æœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _file_index_service
    if _file_index_service is None:
        faiss_path, whoosh_path = settings.get_index_paths()
        _file_index_service = FileIndexService(
            data_root=settings.index.data_root,
            faiss_index_path=faiss_path,
            whoosh_index_path=whoosh_path,
            use_chinese_analyzer=settings.index.use_chinese_analyzer,
            scanner_config={
                'max_workers': settings.index.scanner_max_workers,
                'max_file_size': settings.index.max_file_size,
                'supported_extensions': set(settings.index.supported_extensions)
            },
            parser_config={
                'max_content_length': settings.index.max_content_length
            }
        )
    return get_global_file_index_service()


@router.post("/create", response_model=IndexCreateResponse, summary="åˆ›å»ºç´¢å¼•")
async def create_index(
    request: IndexCreateRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    """
    åˆ›å»ºæ–‡ä»¶ç´¢å¼•

    å¯¹æŒ‡å®šæ–‡ä»¶å¤¹è¿›è¡Œæ–‡ä»¶æ‰«æå’Œç´¢å¼•åˆ›å»º

    - **folder_path**: ç´¢å¼•æ–‡ä»¶å¤¹è·¯å¾„
    - **file_types**: æ”¯æŒæ–‡ä»¶ç±»å‹ï¼ˆå¯é€‰ï¼Œä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼ï¼‰
    - **recursive**: æ˜¯å¦é€’å½’æœç´¢å­æ–‡ä»¶å¤¹
    """
    logger.info(f"åˆ›å»ºç´¢å¼•è¯·æ±‚: folder='{request.folder_path}', recursive={request.recursive}")

    try:
        # éªŒè¯æ–‡ä»¶å¤¹è·¯å¾„
        if not os.path.exists(request.folder_path):
            raise ValidationException(f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {request.folder_path}")

        if not os.path.isdir(request.folder_path):
            raise ValidationException(f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶å¤¹: {request.folder_path}")

        # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„ç´¢å¼•ä»»åŠ¡
        existing_job = db.query(IndexJobModel).filter(
            IndexJobModel.folder_path == request.folder_path,
            IndexJobModel.status.in_([get_enum_value(JobStatus.PENDING), get_enum_value(JobStatus.PROCESSING)])
        ).first()

        if existing_job:
            logger.info(f"æ–‡ä»¶å¤¹å·²åœ¨ç´¢å¼•ä¸­: {request.folder_path}")
            return IndexCreateResponse(
                data=IndexJobInfo(**existing_job.to_dict()),
                message="æ–‡ä»¶å¤¹æ­£åœ¨ç´¢å¼•ä¸­"
            )

        # åˆ›å»ºæ–°çš„ç´¢å¼•ä»»åŠ¡
        index_job = IndexJobModel(
            folder_path=request.folder_path,
            job_type=JobType.CREATE,
            status=get_enum_value(JobStatus.PENDING)
        )
        db.add(index_job)
        db.commit()
        db.refresh(index_job)

        # æ·»åŠ åå°ä»»åŠ¡
        background_tasks.add_task(
            run_full_index_task,
            index_job.id,
            request.folder_path,
            request.recursive,
            request.file_types
        )

        logger.info(f"ç´¢å¼•ä»»åŠ¡å·²åˆ›å»º: id={index_job.id}")

        return IndexCreateResponse(
            data=IndexJobInfo(**index_job.to_dict()),
            message="ç´¢å¼•ä»»åŠ¡å·²åˆ›å»ºå¹¶å¼€å§‹æ‰§è¡Œ"
        )

    except ValidationException:
        raise
    except Exception as e:
        logger.error(f"åˆ›å»ºç´¢å¼•å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºç´¢å¼•å¤±è´¥: {str(e)}")


@router.post("/update", response_model=IndexCreateResponse, summary="æ›´æ–°ç´¢å¼•")
async def update_index(
    request: IndexUpdateRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    """
    å¢é‡æ›´æ–°æ–‡ä»¶ç´¢å¼•

    å¯¹å·²ç´¢å¼•çš„æ–‡ä»¶å¤¹è¿›è¡Œå¢é‡æ›´æ–°ï¼Œåªå¤„ç†æ–°å¢æˆ–ä¿®æ”¹çš„æ–‡ä»¶

    - **folder_path**: ç´¢å¼•æ–‡ä»¶å¤¹è·¯å¾„
    - **recursive**: æ˜¯å¦é€’å½’æœç´¢å­æ–‡ä»¶å¤¹
    """
    logger.info(f"æ›´æ–°ç´¢å¼•è¯·æ±‚: folder='{request.folder_path}'")

    try:
        # éªŒè¯æ–‡ä»¶å¤¹è·¯å¾„
        if not os.path.exists(request.folder_path):
            raise ValidationException(f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {request.folder_path}")

        # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„ç´¢å¼•ä»»åŠ¡
        existing_job = db.query(IndexJobModel).filter(
            IndexJobModel.folder_path == request.folder_path,
            IndexJobModel.status.in_([get_enum_value(JobStatus.PENDING), get_enum_value(JobStatus.PROCESSING)])
        ).first()

        if existing_job:
            logger.info(f"æ–‡ä»¶å¤¹æ­£åœ¨ç´¢å¼•ä¸­: {request.folder_path}")
            return IndexCreateResponse(
                data=IndexJobInfo(**existing_job.to_dict()),
                message="æ–‡ä»¶å¤¹æ­£åœ¨ç´¢å¼•ä¸­"
            )

        # åˆ›å»ºæ›´æ–°ä»»åŠ¡
        index_job = IndexJobModel(
            folder_path=request.folder_path,
            job_type=JobType.UPDATE,
            status=get_enum_value(JobStatus.PENDING)
        )
        db.add(index_job)
        db.commit()
        db.refresh(index_job)

        # æ·»åŠ åå°ä»»åŠ¡
        background_tasks.add_task(
            run_incremental_index_task,
            index_job.id,
            request.folder_path,
            request.recursive,
            request.file_types
        )

        logger.info(f"å¢é‡ç´¢å¼•ä»»åŠ¡å·²åˆ›å»º: id={index_job.id}")

        return IndexCreateResponse(
            data=IndexJobInfo(**index_job.to_dict()),
            message="å¢é‡ç´¢å¼•ä»»åŠ¡å·²åˆ›å»ºå¹¶å¼€å§‹æ‰§è¡Œ"
        )

    except ValidationException:
        raise
    except Exception as e:
        logger.error(f"åˆ›å»ºå¢é‡ç´¢å¼•å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºå¢é‡ç´¢å¼•å¤±è´¥: {str(e)}")


@router.get("/status", summary="è·å–ç´¢å¼•ç³»ç»ŸçŠ¶æ€")
async def get_system_status(
    db: Session = Depends(get_db)
):
    """
    è·å–ç´¢å¼•ç³»ç»Ÿçš„æ•´ä½“çŠ¶æ€

    åŒ…æ‹¬ç»Ÿè®¡ä¿¡æ¯ã€æ”¯æŒçš„æ ¼å¼ã€æœåŠ¡çŠ¶æ€ç­‰
    """
    logger.info("è·å–ç´¢å¼•ç³»ç»ŸçŠ¶æ€")

    try:
        # è·å–æ–‡ä»¶ç´¢å¼•æœåŠ¡
        index_service = get_file_index_service()

        # è·å–ç´¢å¼•ç»Ÿè®¡
        index_stats = index_service.get_index_status()

        # è·å–æ”¯æŒçš„æ ¼å¼
        supported_formats = index_service.get_supported_formats()

        # è·å–æ•°æ®åº“ç»Ÿè®¡
        total_files = db.query(FileModel).count()
        indexed_files = db.query(FileModel).filter(FileModel.is_indexed == True).count()
        pending_files = db.query(FileModel).filter(FileModel.index_status == get_enum_value(JobStatus.PENDING)).count()
        failed_files = db.query(FileModel).filter(FileModel.index_status == get_enum_value(JobStatus.FAILED)).count()

        # è·å–æœ€è¿‘çš„ä»»åŠ¡ç»Ÿè®¡
        recent_jobs = db.query(IndexJobModel).order_by(IndexJobModel.created_at.desc()).limit(10).all()
        job_stats = {
            'total_jobs': len(recent_jobs),
            'completed_jobs': len([j for j in recent_jobs if j.status == get_enum_value(JobStatus.COMPLETED)]),
            'failed_jobs': len([j for j in recent_jobs if j.status == get_enum_value(JobStatus.FAILED)]),
            'processing_jobs': len([j for j in recent_jobs if j.status == get_enum_value(JobStatus.PROCESSING)])
        }

        return {
            "success": True,
            "data": {
                "index_stats": index_stats,
                "supported_formats": supported_formats,
                "database_stats": {
                    "total_files": total_files,
                    "indexed_files": indexed_files,
                    "pending_files": pending_files,
                    "failed_files": failed_files
                },
                "job_stats": job_stats,
                "config": {
                    "max_file_size": settings.index.max_file_size,
                    "use_chinese_analyzer": settings.index.use_chinese_analyzer,
                    "scanner_workers": settings.index.scanner_max_workers
                }
            },
            "message": "è·å–ç´¢å¼•ç³»ç»ŸçŠ¶æ€æˆåŠŸ"
        }

    except Exception as e:
        logger.error(f"è·å–ç´¢å¼•ç³»ç»ŸçŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ç´¢å¼•ç³»ç»ŸçŠ¶æ€å¤±è´¥: {str(e)}")


@router.get("/status/{index_id}", response_model=IndexCreateResponse, summary="æŸ¥è¯¢ç´¢å¼•çŠ¶æ€")
async def get_index_status(
    index_id: int,
    db: Session = Depends(get_db)
):
    """
    è·å–ç´¢å¼•ä»»åŠ¡çŠ¶æ€

    - **index_id**: ç´¢å¼•ä»»åŠ¡ID
    """
    logger.info(f"æŸ¥è¯¢ç´¢å¼•çŠ¶æ€: id={index_id}")

    try:
        # æŸ¥è¯¢ç´¢å¼•ä»»åŠ¡
        index_job = db.query(IndexJobModel).filter(
            IndexJobModel.id == index_id
        ).first()

        if not index_job:
            raise ResourceNotFoundException("ç´¢å¼•ä»»åŠ¡", str(index_id))

        # è·å–æ¨¡å‹å­—å…¸å¹¶è¿‡æ»¤åªä¿ç•™IndexJobInfoéœ€è¦çš„å­—æ®µ
        model_dict = index_job.to_dict()
        job_dict = {
            'index_id': model_dict['index_id'],
            'folder_path': model_dict['folder_path'],
            'status': model_dict['status'],
            'progress': model_dict['progress'],
            'total_files': model_dict['total_files'],
            'processed_files': model_dict['processed_files'],
            'error_count': model_dict['error_count'],
            'started_at': model_dict['started_at'],
            'completed_at': model_dict['completed_at'],
            'error_message': model_dict['error_message']
        }

        logger.info(f"ç´¢å¼•çŠ¶æ€æŸ¥è¯¢å®Œæˆ: id={index_id}, status={index_job.status}")

        return IndexCreateResponse(
            data=IndexJobInfo(**job_dict),
            message="ç´¢å¼•çŠ¶æ€æŸ¥è¯¢æˆåŠŸ"
        )

    except ResourceNotFoundException:
        raise
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ç´¢å¼•çŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢ç´¢å¼•çŠ¶æ€å¤±è´¥: {str(e)}")


@router.get("/list", response_model=IndexListResponse, summary="ç´¢å¼•åˆ—è¡¨")
async def get_index_list(
    status: Optional[JobStatus] = None,
    limit: int = 10,
    offset: int = 0,
    db: Session = Depends(get_db)
):
    """
    è·å–ç´¢å¼•ä»»åŠ¡åˆ—è¡¨

    - **status**: ä»»åŠ¡çŠ¶æ€è¿‡æ»¤
    - **limit**: è¿”å›ç»“æœæ•°é‡
    - **offset**: åç§»é‡
    """
    logger.info(f"è·å–ç´¢å¼•åˆ—è¡¨: status={status}, limit={limit}, offset={offset}")

    try:
        # æ„å»ºæŸ¥è¯¢
        query = db.query(IndexJobModel)

        # åº”ç”¨è¿‡æ»¤æ¡ä»¶
        if status:
            query = query.filter(IndexJobModel.status == get_enum_value(status))

        # è·å–æ€»æ•°
        total = query.count()

        # åˆ†é¡µæŸ¥è¯¢
        index_jobs = query.order_by(
            IndexJobModel.created_at.desc()
        ).offset(offset).limit(limit).all()

        # è½¬æ¢ä¸ºå“åº”æ ¼å¼
        job_list = [
            IndexJobInfo(**job.to_dict())
            for job in index_jobs
        ]

        logger.info(f"è¿”å›ç´¢å¼•åˆ—è¡¨: æ•°é‡={len(job_list)}, æ€»è®¡={total}")

        return IndexListResponse(
            data={
                "indexes": [job.dict() for job in job_list],
                "total": total,
                "limit": limit,
                "offset": offset
            },
            message="è·å–ç´¢å¼•åˆ—è¡¨æˆåŠŸ"
        )

    except Exception as e:
        logger.error(f"è·å–ç´¢å¼•åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ç´¢å¼•åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.delete("/{index_id}", response_model=SuccessResponse, summary="åˆ é™¤ç´¢å¼•")
async def delete_index(
    index_id: int,
    db: Session = Depends(get_db)
):
    """
    åˆ é™¤ç´¢å¼•ä»»åŠ¡å’Œç›¸å…³æ•°æ®

    - **index_id**: ç´¢å¼•ä»»åŠ¡ID
    """
    logger.info(f"åˆ é™¤ç´¢å¼•: id={index_id}")

    try:
        # æŸ¥è¯¢ç´¢å¼•ä»»åŠ¡
        index_job = db.query(IndexJobModel).filter(
            IndexJobModel.id == index_id
        ).first()

        if not index_job:
            raise ResourceNotFoundException("ç´¢å¼•ä»»åŠ¡", str(index_id))

        folder_path = index_job.folder_path

        # å¦‚æœä»»åŠ¡æ­£åœ¨è¿è¡Œï¼Œæ ‡è®°ä¸ºå¤±è´¥
        if index_job.status == get_enum_value(JobStatus.PROCESSING):
            index_job.fail_job("ä»»åŠ¡è¢«æ‰‹åŠ¨åˆ é™¤")
            logger.info(f"åœæ­¢æ­£åœ¨è¿è¡Œçš„ç´¢å¼•ä»»åŠ¡: id={index_id}")

        # åˆ é™¤ç›¸å…³çš„æ–‡ä»¶ç´¢å¼•è®°å½•
        deleted_files = db.query(FileModel).filter(
            FileModel.file_path.like(f"{folder_path}%")
        ).count()
        db.query(FileModel).filter(
            FileModel.file_path.like(f"{folder_path}%")
        ).delete()

        # åˆ é™¤ç´¢å¼•ä»»åŠ¡
        db.delete(index_job)
        db.commit()

        logger.info(f"ç´¢å¼•åˆ é™¤å®Œæˆ: id={index_id}, åˆ é™¤æ–‡ä»¶æ•°={deleted_files}")

        return SuccessResponse(
            data={
                "deleted_index_id": index_id,
                "deleted_files_count": deleted_files,
                "folder_path": folder_path
            },
            message="ç´¢å¼•åˆ é™¤æˆåŠŸ"
        )

    except ResourceNotFoundException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤ç´¢å¼•å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤ç´¢å¼•å¤±è´¥: {str(e)}")


@router.post("/{index_id}/stop", response_model=SuccessResponse, summary="åœæ­¢ç´¢å¼•")
async def stop_index(
    index_id: int,
    db: Session = Depends(get_db)
):
    """
    åœæ­¢æ­£åœ¨è¿è¡Œçš„ç´¢å¼•ä»»åŠ¡

    - **index_id**: ç´¢å¼•ä»»åŠ¡ID
    """
    logger.info(f"åœæ­¢ç´¢å¼•ä»»åŠ¡: id={index_id}")

    try:
        # æŸ¥è¯¢ç´¢å¼•ä»»åŠ¡
        index_job = db.query(IndexJobModel).filter(
            IndexJobModel.id == index_id
        ).first()

        if not index_job:
            raise ResourceNotFoundException("ç´¢å¼•ä»»åŠ¡", str(index_id))

        if index_job.status != get_enum_value(JobStatus.PROCESSING):
            raise ValidationException("åªèƒ½åœæ­¢æ­£åœ¨è¿è¡Œçš„ç´¢å¼•ä»»åŠ¡")

        # æ ‡è®°ä»»åŠ¡ä¸ºå¤±è´¥
        index_job.fail_job("ä»»åŠ¡è¢«æ‰‹åŠ¨åœæ­¢")
        db.commit()

        logger.info(f"ç´¢å¼•ä»»åŠ¡å·²åœæ­¢: id={index_id}")

        return SuccessResponse(
            data={
                "stopped_index_id": index_id,
                "processed_files": index_job.processed_files,
                "total_files": index_job.total_files
            },
            message="ç´¢å¼•ä»»åŠ¡å·²åœæ­¢"
        )

    except (ResourceNotFoundException, ValidationException):
        raise
    except Exception as e:
        logger.error(f"åœæ­¢ç´¢å¼•ä»»åŠ¡å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åœæ­¢ç´¢å¼•ä»»åŠ¡å¤±è´¥: {str(e)}")


@router.post("/backup", response_model=SuccessResponse, summary="å¤‡ä»½ç´¢å¼•")
async def backup_index(
    backup_name: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """
    å¤‡ä»½å½“å‰ç´¢å¼•

    - **backup_name**: å¤‡ä»½åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨æ—¶é—´æˆ³ï¼‰
    """
    logger.info(f"å¤‡ä»½ç´¢å¼•: name={backup_name}")

    try:
        # è·å–æ–‡ä»¶ç´¢å¼•æœåŠ¡
        index_service = get_file_index_service()

        # æ‰§è¡Œå¤‡ä»½
        backup_result = index_service.backup_indexes(backup_name)

        if backup_result['success']:
            return SuccessResponse(
                data=backup_result,
                message="ç´¢å¼•å¤‡ä»½æˆåŠŸ"
            )
        else:
            raise HTTPException(status_code=500, detail="ç´¢å¼•å¤‡ä»½å¤±è´¥")

    except Exception as e:
        logger.error(f"å¤‡ä»½ç´¢å¼•å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¤‡ä»½ç´¢å¼•å¤±è´¥: {str(e)}")


@router.get("/files", summary="å·²ç´¢å¼•æ–‡ä»¶åˆ—è¡¨")
async def get_indexed_files(
    folder_path: Optional[str] = None,
    file_type: Optional[str] = None,
    index_status: Optional[str] = None,
    limit: int = 20,
    offset: int = 0,
    db: Session = Depends(get_db)
):
    """
    è·å–å·²ç´¢å¼•çš„æ–‡ä»¶åˆ—è¡¨

    - **folder_path**: æ–‡ä»¶å¤¹è·¯å¾„è¿‡æ»¤
    - **file_type**: æ–‡ä»¶ç±»å‹è¿‡æ»¤
    - **index_status**: ç´¢å¼•çŠ¶æ€è¿‡æ»¤
    - **limit**: è¿”å›ç»“æœæ•°é‡
    - **offset**: åç§»é‡
    """
    logger.info(f"è·å–å·²ç´¢å¼•æ–‡ä»¶: folder={folder_path}, type={file_type}, status={index_status}")

    try:
        # æ„å»ºæŸ¥è¯¢
        query = db.query(FileModel)

        # åº”ç”¨è¿‡æ»¤æ¡ä»¶
        if folder_path:
            query = query.filter(FileModel.file_path.like(f"{folder_path}%"))
        if file_type:
            query = query.filter(FileModel.file_type == file_type)
        if index_status:
            query = query.filter(FileModel.index_status == index_status)

        # è·å–æ€»æ•°
        total = query.count()

        # åˆ†é¡µæŸ¥è¯¢
        files = query.order_by(
            FileModel.indexed_at.desc()
        ).offset(offset).limit(limit).all()

        # è½¬æ¢ä¸ºå“åº”æ ¼å¼
        file_list = [file.to_dict() for file in files]

        logger.info(f"è¿”å›å·²ç´¢å¼•æ–‡ä»¶: æ•°é‡={len(file_list)}, æ€»è®¡={total}")

        return {
            "success": True,
            "data": {
                "files": file_list,
                "total": total,
                "limit": limit,
                "offset": offset
            },
            "message": "è·å–å·²ç´¢å¼•æ–‡ä»¶æˆåŠŸ"
        }

    except Exception as e:
        logger.error(f"è·å–å·²ç´¢å¼•æ–‡ä»¶å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–å·²ç´¢å¼•æ–‡ä»¶å¤±è´¥: {str(e)}")


@router.delete("/files/{file_id}", response_model=SuccessResponse, summary="åˆ é™¤æ–‡ä»¶ç´¢å¼•")
async def delete_file_index(
    file_id: int,
    db: Session = Depends(get_db)
):
    """
    ä»ç´¢å¼•ä¸­åˆ é™¤å•ä¸ªæ–‡ä»¶

    - **file_id**: æ–‡ä»¶ID
    """
    logger.info(f"åˆ é™¤æ–‡ä»¶ç´¢å¼•: file_id={file_id}")

    try:
        # æŸ¥è¯¢æ–‡ä»¶
        file_model = db.query(FileModel).filter(
            FileModel.id == file_id
        ).first()

        if not file_model:
            raise ResourceNotFoundException("æ–‡ä»¶", str(file_id))

        # ä»ç´¢å¼•æœåŠ¡ä¸­åˆ é™¤
        index_service = get_file_index_service()
        delete_result = index_service.delete_file_from_index(file_model.file_path)

        if delete_result['success']:
            # ä»æ•°æ®åº“ä¸­åˆ é™¤è®°å½•
            db.delete(file_model)
            db.commit()

            return SuccessResponse(
                data={
                    "deleted_file_id": file_id,
                    "file_path": file_model.file_path
                },
                message="æ–‡ä»¶ç´¢å¼•åˆ é™¤æˆåŠŸ"
            )
        else:
            raise HTTPException(status_code=500, detail="ä»ç´¢å¼•ä¸­åˆ é™¤æ–‡ä»¶å¤±è´¥")

    except ResourceNotFoundException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤æ–‡ä»¶ç´¢å¼•å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤æ–‡ä»¶ç´¢å¼•å¤±è´¥: {str(e)}")


async def run_full_index_task(
    index_id: int,
    folder_path: str,
    recursive: bool = True,
    file_types: Optional[List[str]] = None
):
    """
    æ‰§è¡Œå®Œæ•´ç´¢å¼•ä»»åŠ¡ï¼ˆåå°ä»»åŠ¡ï¼‰

    Args:
        index_id: ç´¢å¼•ä»»åŠ¡ID
        folder_path: æ–‡ä»¶å¤¹è·¯å¾„
        recursive: æ˜¯å¦é€’å½’æœç´¢
        file_types: æŒ‡å®šæ–‡ä»¶ç±»å‹è¿‡æ»¤åˆ—è¡¨ï¼Œä¸ºNoneæ—¶ä½¿ç”¨é»˜è®¤é…ç½®
    """
    logger.info(f"å¼€å§‹æ‰§è¡Œå®Œæ•´ç´¢å¼•ä»»åŠ¡: id={index_id}, folder={folder_path}")

    from app.core.database import SessionLocal

    # è·å–æ•°æ®åº“ä¼šè¯
    db = SessionLocal()
    try:
        # è·å–ç´¢å¼•ä»»åŠ¡
        index_job = db.query(IndexJobModel).filter(
            IndexJobModel.id == index_id
        ).first()

        if not index_job or index_job.status != get_enum_value(JobStatus.PENDING):
            logger.warning(f"ç´¢å¼•ä»»åŠ¡ä¸å­˜åœ¨æˆ–çŠ¶æ€ä¸æ­£ç¡®: id={index_id}")
            return

        # å¼€å§‹ä»»åŠ¡
        index_job.start_job()
        db.commit()

        # å®šä¹‰è¿›åº¦å›è°ƒ
        def progress_callback(message: str, progress: float):
            logger.info(f"ç´¢å¼•è¿›åº¦[{index_id}]: {message} - {progress:.1f}%")
            # æ›´æ–°ä»»åŠ¡è¿›åº¦ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            if index_job.total_files > 0:
                processed = int((progress / 100) * index_job.total_files)
                index_job.update_progress(processed)
                db.commit()

        # å¤„ç†æ–‡ä»¶ç±»å‹è¿‡æ»¤ï¼šå¦‚æœæœªæŒ‡å®šfile_typesï¼Œåˆ™ä½¿ç”¨DefaultConfigæ”¯æŒçš„æ‰€æœ‰ç±»å‹
        if file_types:
            # å°†æ–‡ä»¶ç±»å‹æ‰©å±•åæ ¼å¼ç»Ÿä¸€
            filtered_extensions = set()
            for ext in file_types:
                if not ext.startswith('.'):
                    ext = '.' + ext
                filtered_extensions.add(ext.lower())
            logger.info(f"ä½¿ç”¨æŒ‡å®šçš„æ–‡ä»¶ç±»å‹è¿‡æ»¤: {filtered_extensions}")
        else:
            # ä½¿ç”¨DefaultConfigæ”¯æŒçš„æ‰€æœ‰æ–‡ä»¶ç±»å‹
            filtered_extensions = settings.default.get_supported_extensions()
            logger.info(f"ä½¿ç”¨DefaultConfigé»˜è®¤æ”¯æŒçš„æ‰€æœ‰æ–‡ä»¶ç±»å‹: {filtered_extensions}")

        # ä½¿ç”¨å…¨å±€å•ä¾‹ç´¢å¼•æœåŠ¡
        temp_index_service = get_global_file_index_service()

        result = await temp_index_service.build_full_index(
            scan_paths=[folder_path],
            progress_callback=progress_callback
        )

        # æ›´æ–°ä»»åŠ¡ç»“æœ
        if result['success']:
            index_job.total_files = result.get('total_files_found', 0)
            index_job.processed_files = result.get('documents_indexed', 0)
            index_job.error_count = result.get('failed_files', 0)
            index_job.complete_job()
            logger.info(f"å®Œæ•´ç´¢å¼•ä»»åŠ¡å®Œæˆ: id={index_id}, æˆåŠŸç´¢å¼• {index_job.processed_files} ä¸ªæ–‡ä»¶")
        else:
            index_job.fail_job(result.get('error', 'æœªçŸ¥é”™è¯¯'))
            logger.error(f"å®Œæ•´ç´¢å¼•ä»»åŠ¡å¤±è´¥: id={index_id}, é”™è¯¯: {result.get('error')}")

        db.commit()

    except Exception as e:
        logger.error(f"å®Œæ•´ç´¢å¼•ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}")
        if index_job:
            index_job.fail_job(str(e))
            db.commit()
    finally:
        db.close()


async def run_incremental_index_task(
    index_id: int,
    folder_path: str,
    recursive: bool = True,
    file_types: Optional[List[str]] = None
):
    """
    æ‰§è¡Œå¢é‡ç´¢å¼•ä»»åŠ¡ï¼ˆåå°ä»»åŠ¡ï¼‰

    Args:
        index_id: ç´¢å¼•ä»»åŠ¡ID
        folder_path: æ–‡ä»¶å¤¹è·¯å¾„
        recursive: æ˜¯å¦é€’å½’æœç´¢
        file_types: æŒ‡å®šæ–‡ä»¶ç±»å‹è¿‡æ»¤åˆ—è¡¨ï¼Œä¸ºNoneæ—¶ä½¿ç”¨é»˜è®¤é…ç½®
    """
    # ğŸ”§ ç¡®ä¿åå°ä»»åŠ¡çš„æ—¥å¿—èƒ½å¤Ÿè¾“å‡ºåˆ°æ§åˆ¶å°
    import logging
    import sys

    # å¼ºåˆ¶æ·»åŠ æ§åˆ¶å°å¤„ç†å™¨ï¼ˆç¡®ä¿åå°ä»»åŠ¡æ—¥å¿—èƒ½æ˜¾ç¤ºåœ¨ç»ˆç«¯ï¼‰
    root_logger = logging.getLogger()

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ§åˆ¶å°å¤„ç†å™¨
    has_console_handler = any(
        isinstance(h, logging.StreamHandler) and h.stream == sys.stdout
        for h in root_logger.handlers
    )

    if not has_console_handler:
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)
        console_formatter = logging.Formatter(
            fmt="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S"
        )
        console_handler.setFormatter(console_formatter)
        # æ·»åŠ åˆ°æ ¹æ—¥å¿—å™¨ï¼Œä¸é˜»æ­¢å…¶ä»–å¤„ç†å™¨
        root_logger.addHandler(console_handler)
        root_logger.info("ğŸ”§ åå°ä»»åŠ¡æ§åˆ¶å°æ—¥å¿—å¤„ç†å™¨å·²æ·»åŠ ")

    # ç¡®ä¿å½“å‰æ¨¡å—çš„loggerä¹Ÿèƒ½è¾“å‡ºåˆ°æ§åˆ¶å°
    current_logger = logging.getLogger(__name__)
    current_logger.setLevel(logging.INFO)

    # æµ‹è¯•æ—¥å¿—è¾“å‡º
    print(f"ğŸš€ å¢é‡ç´¢å¼•ä»»åŠ¡å¼€å§‹: id={index_id}", flush=True)

    logger.info(f"å¼€å§‹æ‰§è¡Œå¢é‡ç´¢å¼•ä»»åŠ¡: id={index_id}, folder={folder_path}")

    from app.core.database import SessionLocal

    # è·å–æ•°æ®åº“ä¼šè¯
    db = SessionLocal()
    try:
        # è·å–ç´¢å¼•ä»»åŠ¡
        index_job = db.query(IndexJobModel).filter(
            IndexJobModel.id == index_id
        ).first()

        if not index_job or index_job.status != get_enum_value(JobStatus.PENDING):
            logger.warning(f"å¢é‡ç´¢å¼•ä»»åŠ¡ä¸å­˜åœ¨æˆ–çŠ¶æ€ä¸æ­£ç¡®: id={index_id}")
            return

        # å¼€å§‹ä»»åŠ¡
        index_job.start_job()
        db.commit()

        # å¤„ç†æ–‡ä»¶ç±»å‹è¿‡æ»¤ï¼šå¦‚æœæœªæŒ‡å®šfile_typesï¼Œåˆ™ä½¿ç”¨DefaultConfigæ”¯æŒçš„æ‰€æœ‰ç±»å‹
        if file_types:
            # å°†æ–‡ä»¶ç±»å‹æ‰©å±•åæ ¼å¼ç»Ÿä¸€
            filtered_extensions = set()
            for ext in file_types:
                if not ext.startswith('.'):
                    ext = '.' + ext
                filtered_extensions.add(ext.lower())
            logger.info(f"å¢é‡ç´¢å¼•ä½¿ç”¨æŒ‡å®šçš„æ–‡ä»¶ç±»å‹è¿‡æ»¤: {filtered_extensions}")
        else:
            # ä½¿ç”¨DefaultConfigæ”¯æŒçš„æ‰€æœ‰æ–‡ä»¶ç±»å‹
            filtered_extensions = settings.default.get_supported_extensions()
            logger.info(f"å¢é‡ç´¢å¼•ä½¿ç”¨DefaultConfigé»˜è®¤æ”¯æŒçš„æ‰€æœ‰æ–‡ä»¶ç±»å‹: {filtered_extensions}")

        # ä½¿ç”¨å…¨å±€å•ä¾‹ç´¢å¼•æœåŠ¡
        temp_index_service = get_global_file_index_service()

        result = await temp_index_service.update_incremental_index(
            scan_paths=[folder_path]
        )

        # æ›´æ–°ä»»åŠ¡ç»“æœ
        if result['success']:
            index_job.total_files = result.get('changed_files', 0) + result.get('deleted_files', 0)
            index_job.processed_files = result.get('changed_files', 0)
            index_job.error_count = 0  # å¢é‡æ›´æ–°é€šå¸¸ä¸ä¼šæœ‰é”™è¯¯
            index_job.complete_job()
            logger.info(f"å¢é‡ç´¢å¼•ä»»åŠ¡å®Œæˆ: id={index_id}, å¤„ç† {index_job.processed_files} ä¸ªå˜æ›´æ–‡ä»¶")
        else:
            index_job.fail_job(result.get('error', 'æœªçŸ¥é”™è¯¯'))
            logger.error(f"å¢é‡ç´¢å¼•ä»»åŠ¡å¤±è´¥: id={index_id}, é”™è¯¯: {result.get('error')}")

        db.commit()

    except Exception as e:
        logger.error(f"å¢é‡ç´¢å¼•ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}")
        if index_job:
            index_job.fail_job(str(e))
            db.commit()
    finally:
        db.close()