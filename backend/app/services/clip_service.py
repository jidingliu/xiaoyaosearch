"""
CN-CLIP图像理解模型服务
提供中文图像-文本理解和匹配功能
"""
import asyncio
import logging
import os
import tempfile
import time
from typing import Dict, Any, Optional, List, Union, Tuple, BinaryIO
from pathlib import Path
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image, ImageOps
from transformers import CLIPProcessor, CLIPModel, ChineseCLIPProcessor, ChineseCLIPModel
import requests
from io import BytesIO

from app.services.ai_model_base import BaseAIModel, ModelType, ProviderType, ModelStatus, AIModelException
from app.utils.enum_helpers import get_enum_value

logger = logging.getLogger(__name__)


class CLIPVisionService(BaseAIModel):
    """
    CN-CLIP图像理解服务

    提供中文图像-文本理解和匹配功能
    """

    def __init__(self, config: Dict[str, Any] = None):
        """
        初始化CLIP图像理解服务

        Args:
            config: 模型配置参数
        """
        default_config = {
            "model_name": "OFA-Sys/chinese-clip-vit-base-patch16",
            "device": "cpu",
            "max_image_size": 512,
            "supported_formats": [".jpg", ".jpeg", ".png", ".bmp", ".tiff", ".webp"],
            "max_file_size": 10 * 1024 * 1024,  # 10MB
            "normalize_embeddings": True,
            "batch_size": 16,
            "use_chinese_clip": True
        }

        if config:
            default_config.update(config)

        super().__init__(
            model_name=default_config["model_name"],
            model_type=ModelType.VISION,
            provider=ProviderType.LOCAL,
            config=default_config
        )

        # 模型相关属性
        self.model = None
        self.processor = None
        self.device = self._setup_device()

        logger.info(f"初始化CLIP图像理解服务，模型: {self.config['model_name']}")

    def _setup_device(self) -> torch.device:
        """
        设置计算设备

        Returns:
            torch.device: 计算设备
        """
        device_str = self.config.get("device", "cpu")
        if device_str == "auto":
            device_str = "cuda" if torch.cuda.is_available() else "cpu"

        device = torch.device(device_str)

        if device_str == "cuda":
            logger.info(f"使用GPU设备: {torch.cuda.get_device_name()}")
        else:
            logger.info("使用CPU设备")

        return device

    async def load_model(self) -> bool:
        """
        加载CLIP模型

        Returns:
            bool: 加载是否成功
        """
        try:
            self.update_status(ModelStatus.LOADING)
            logger.info(f"开始加载CLIP模型: {self.model_name}")

            # 在线程池中执行模型加载
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(None, self._load_model_sync)

            self.update_status(ModelStatus.LOADED)
            logger.info(f"CLIP模型加载成功，模型: {self.config['model_name']}")
            return True

        except Exception as e:
            error_msg = f"CLIP模型加载失败: {str(e)}"
            logger.error(error_msg)
            self.update_status(ModelStatus.ERROR, error_msg)
            raise AIModelException(error_msg, model_name=self.model_name)

    def _load_model_sync(self):
        """同步加载模型"""
        model_name = self.config["model_name"]

        logger.info(f"下载并加载CLIP模型 {model_name} 到 {self.device}")

        # 加载CLIP模型和处理器
        # 使用Chinese-CLIP模型和处理器
        self.model = ChineseCLIPModel.from_pretrained(model_name)
        self.processor = ChineseCLIPProcessor.from_pretrained(model_name)

        # 移动模型到指定设备
        self.model.to(self.device)
        self.model.eval()  # 设置为评估模式

        logger.info("CLIP模型加载完成")

    async def unload_model(self) -> bool:
        """
        卸载CLIP模型

        Returns:
            bool: 卸载是否成功
        """
        try:
            logger.info(f"开始卸载CLIP模型: {self.model_name}")

            # 清理模型
            if self.model:
                del self.model
                self.model = None

            if self.processor:
                del self.processor
                self.processor = None

            # 清理GPU内存
            if self.device.type == "cuda":
                torch.cuda.empty_cache()

            self.update_status(ModelStatus.UNLOADED)
            logger.info("CLIP模型卸载成功")
            return True

        except Exception as e:
            error_msg = f"CLIP模型卸载失败: {str(e)}"
            logger.error(error_msg)
            return False

    async def predict(self, inputs: Union[str, bytes, BinaryIO, Image.Image], texts: List[str], **kwargs) -> Dict[str, Any]:
        """
        图像-文本匹配预测

        Args:
            inputs: 图像输入，可以是文件路径、字节数据、文件对象或PIL Image
            texts: 文本列表
            **kwargs: 其他预测参数
                - return_logits: 是否返回原始logits
                - normalize_embeddings: 是否归一化嵌入向量

        Returns:
            Dict[str, Any]: 预测结果，包含相似度分数等

        Raises:
            AIModelException: 预测失败时抛出异常
        """
        if self.status != ModelStatus.LOADED:
            raise AIModelException(
                f"模型未加载，当前状态: {get_enum_value(self.status)}",
                model_name=self.model_name
            )

        try:
            if not texts:
                raise AIModelException("文本列表不能为空", model_name=self.model_name)

            # 预处理图像输入
            image = await self._preprocess_image(inputs)

            # 获取预测参数
            return_logits = kwargs.get("return_logits", False)
            normalize_embeddings = kwargs.get("normalize_embeddings", self.config.get("normalize_embeddings", True))

            logger.info(f"开始图像-文本匹配，图像: {type(inputs)}, 文本数量: {len(texts)}")

            # 在线程池中执行预测
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                None, self._match_sync, image, texts, return_logits, normalize_embeddings
            )

            self.record_usage()
            logger.info(f"图像-文本匹配完成，最佳匹配: {result['best_match']['text']}")
            return result

        except Exception as e:
            error_msg = f"图像-文本匹配失败: {str(e)}"
            logger.error(error_msg)
            raise AIModelException(error_msg, model_name=self.model_name)

    async def _preprocess_image(self, image_input: Union[str, bytes, BinaryIO, Image.Image]) -> Image.Image:
        """
        预处理图像输入

        Args:
            image_input: 图像输入

        Returns:
            Image.Image: 处理后的PIL图像
        """
        # 如果已经是PIL图像
        if isinstance(image_input, Image.Image):
            return image_input.convert("RGB")

        # 如果是文件路径
        elif isinstance(image_input, str):
            if image_input.startswith(("http://", "https://")):
                # 网络图片
                return await self._load_image_from_url(image_input)
            else:
                # 本地文件
                if not os.path.exists(image_input):
                    raise AIModelException(f"图像文件不存在: {image_input}", model_name=self.model_name)

                # 检查文件大小
                file_size = os.path.getsize(image_input)
                if file_size > self.config.get("max_file_size", 10 * 1024 * 1024):
                    raise AIModelException(
                        f"图像文件过大，当前大小: {file_size} bytes，最大限制: {self.config['max_file_size']} bytes",
                        model_name=self.model_name
                    )

                # 检查文件格式
                file_ext = Path(image_input).suffix.lower()
                if file_ext not in self.config.get("supported_formats", []):
                    raise AIModelException(
                        f"不支持的图像格式: {file_ext}，支持的格式: {self.config['supported_formats']}",
                        model_name=self.model_name
                    )

                return Image.open(image_input).convert("RGB")

        # 如果是字节数据或文件对象
        elif isinstance(image_input, (bytes, BinaryIO)):
            try:
                if isinstance(image_input, bytes):
                    image = Image.open(BytesIO(image_input))
                else:
                    image_input.seek(0)
                    image = Image.open(image_input)

                return image.convert("RGB")

            except Exception as e:
                raise AIModelException(f"打开图像数据失败: {str(e)}", model_name=self.model_name)

        else:
            raise AIModelException(f"不支持的图像输入类型: {type(image_input)}", model_name=self.model_name)

    async def _load_image_from_url(self, url: str) -> Image.Image:
        """
        从URL加载图像

        Args:
            url: 图像URL

        Returns:
            Image.Image: PIL图像
        """
        try:
            # 在线程池中执行网络请求
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(None, requests.get, url, {"timeout": 10})

            response.raise_for_status()
            image = Image.open(BytesIO(response.content))
            return image.convert("RGB")

        except Exception as e:
            raise AIModelException(f"从URL加载图像失败: {str(e)}", model_name=self.model_name)

    def _match_sync(self, image: Image.Image, texts: List[str], return_logits: bool, normalize_embeddings: bool) -> Dict[str, Any]:
        """
        同步执行图像-文本匹配

        Args:
            image: PIL图像
            texts: 文本列表
            return_logits: 是否返回原始logits
            normalize_embeddings: 是否归一化

        Returns:
            Dict[str, Any]: 匹配结果
        """
        start_time = time.time()

        # 图像预处理
        max_size = self.config.get("max_image_size", 512)
        image = self._resize_image_keep_ratio(image, max_size)

        # 逐个处理每个文本，避免维度问题
        similarities = []

        for text in texts:
            try:
                # 使用Chinese-CLIP处理单个图像和文本
                inputs = self.processor(
                    text=[text],  # 只处理一个文本
                    images=image,
                    padding=True,
                    return_tensors="pt"
                )
                inputs = {k: v.to(self.device) for k, v in inputs.items()}

                with torch.no_grad():
                    outputs = self.model(**inputs)

                    # 获取相似度分数
                    if hasattr(outputs, 'logits_per_image') and outputs.logits_per_image is not None:
                        similarity = outputs.logits_per_image.cpu().numpy()
                    elif hasattr(outputs, 'logits_per_text') and outputs.logits_per_text is not None:
                        similarity = outputs.logits_per_text.T.cpu().numpy()
                    else:
                        # 如果没有logits，使用简单的默认相似度
                        similarity = np.array([[0.5]])  # 默认中等相似度

                    # 确保similarity是标量
                    if similarity.ndim >= 2:
                        similarity = similarity[0, 0]  # 取第一个值
                    elif similarity.ndim == 1:
                        similarity = similarity[0]

                similarities.append(float(similarity))

            except Exception as e:
                logger.warning(f"处理文本 '{text}' 时出错: {str(e)}, 使用默认相似度")
                similarities.append(0.0)  # 默认相似度

        # 转换为numpy数组
        similarities_array = np.array(similarities)  # [len(texts)]

        # 获取最佳匹配
        best_idx = np.argmax(similarities_array)
        best_match = {
            "index": int(best_idx),
            "text": texts[best_idx],
            "similarity": float(similarities_array[best_idx])
        }

        # 构建结果
        result = {
            "best_match": best_match,
            "all_matches": [
                {
                    "index": i,
                    "text": texts[i],
                    "similarity": float(similarities_array[i]),
                    "logit": float(similarities_array[i]) if return_logits else None
                }
                for i in range(len(texts))
            ],
            "image_embedding": similarities_array.tolist(),
            "text_embeddings": np.eye(len(texts)).tolist(),  # 单位矩阵作为占位符
            "processing_time": time.time() - start_time,
            "model_name": self.model_name
        }

        return result

    def _resize_image_keep_ratio(self, image: Image.Image, max_size: int) -> Image.Image:
        """
        保持长宽比调整图像大小

        Args:
            image: 输入图像
            max_size: 最大尺寸

        Returns:
            Image.Image: 调整后的图像
        """
        # 转换为RGB（处理RGBA等格式）
        if image.mode != "RGB":
            image = image.convert("RGB")

        # 获取原始尺寸
        width, height = image.size

        # 计算缩放比例
        if max(width, height) > max_size:
            if width > height:
                new_width = max_size
                new_height = int(height * max_size / width)
            else:
                new_height = max_size
                new_width = int(width * max_size / height)

            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)

        return image

    async def encode_image(self, image_input: Union[str, bytes, BinaryIO, Image.Image]) -> np.ndarray:
        """
        编码图像为嵌入向量

        Args:
            image_input: 图像输入

        Returns:
            np.ndarray: 图像嵌入向量
        """
        if self.status != ModelStatus.LOADED:
            raise AIModelException(
                f"模型未加载，当前状态: {get_enum_value(self.status)}",
                model_name=self.model_name
            )

        try:
            # 预处理图像
            image = await self._preprocess_image(image_input)

            # 调整图像大小
            max_size = self.config.get("max_image_size", 512)
            image = self._resize_image_keep_ratio(image, max_size)

            # 在线程池中执行编码
            loop = asyncio.get_event_loop()
            embedding = await loop.run_in_executor(None, self._encode_image_sync, image)

            return embedding

        except Exception as e:
            error_msg = f"图像编码失败: {str(e)}"
            logger.error(error_msg)
            raise AIModelException(error_msg, model_name=self.model_name)

    def _encode_image_sync(self, image: Image.Image) -> np.ndarray:
        """同步执行图像编码"""
        inputs = self.processor(images=image, return_tensors="pt")
        inputs = {k: v.to(self.device) for k, v in inputs.items()}

        with torch.no_grad():
            outputs = self.model.get_image_features(**inputs)

        # 归一化
        if self.config.get("normalize_embeddings", True):
            outputs = F.normalize(outputs, p=2, dim=-1)

        return outputs.cpu().numpy().flatten()

    async def encode_text(self, texts: List[str]) -> np.ndarray:
        """
        编码文本为嵌入向量

        Args:
            texts: 文本列表

        Returns:
            np.ndarray: 文本嵌入向量矩阵
        """
        if self.status != ModelStatus.LOADED:
            raise AIModelException(
                f"模型未加载，当前状态: {get_enum_value(self.status)}",
                model_name=self.model_name
            )

        try:
            # 在线程池中执行编码
            loop = asyncio.get_event_loop()
            embeddings = await loop.run_in_executor(None, self._encode_text_sync, texts)

            return embeddings

        except Exception as e:
            error_msg = f"文本编码失败: {str(e)}"
            logger.error(error_msg)
            raise AIModelException(error_msg, model_name=self.model_name)

    def _encode_text_sync(self, texts: List[str]) -> np.ndarray:
        """同步执行文本编码"""
        inputs = self.processor(text=texts, return_tensors="pt", padding=True, truncation=True)
        inputs = {k: v.to(self.device) for k, v in inputs.items()}

        with torch.no_grad():
            outputs = self.model.get_text_features(**inputs)

        # 归一化
        if self.config.get("normalize_embeddings", True):
            outputs = F.normalize(outputs, p=2, dim=-1)

        return outputs.cpu().numpy()

    async def search_images_by_text(self, query: str, image_embeddings: np.ndarray, top_k: int = 10) -> List[Dict[str, Any]]:
        """
        根据文本搜索相似图像

        Args:
            query: 查询文本
            image_embeddings: 图像嵌入矩阵 [n_images, embed_dim]
            top_k: 返回Top-K结果

        Returns:
            List[Dict[str, Any]]: 相似图像列表
        """
        try:
            # 编码查询文本
            text_embedding = await self.encode_text([query])
            text_embedding = text_embedding.flatten()

            # 计算相似度
            similarities = np.dot(image_embeddings, text_embedding)

            # 获取Top-K结果
            top_indices = np.argsort(similarities)[::-1][:top_k]

            results = []
            for idx in top_indices:
                results.append({
                    "index": int(idx),
                    "similarity": float(similarities[idx])
                })

            return results

        except Exception as e:
            error_msg = f"文本搜索图像失败: {str(e)}"
            logger.error(error_msg)
            raise AIModelException(error_msg, model_name=self.model_name)

    async def batch_match(self, image_inputs: List[Union[str, bytes, BinaryIO, Image.Image]], texts: List[str], **kwargs) -> List[Dict[str, Any]]:
        """
        批量图像-文本匹配

        Args:
            image_inputs: 图像输入列表
            texts: 文本列表
            **kwargs: 其他参数

        Returns:
            List[Dict[str, Any]]: 匹配结果列表
        """
        results = []
        for i, image_input in enumerate(image_inputs):
            try:
                result = await self.predict(image_input, texts, **kwargs)
                result["batch_index"] = i
                results.append(result)
            except Exception as e:
                logger.error(f"批量匹配第{i}个图像失败: {str(e)}")
                results.append({
                    "batch_index": i,
                    "error": str(e),
                    "success": False
                })

        return results

    def get_model_info(self) -> Dict[str, Any]:
        """
        获取模型信息

        Returns:
            Dict[str, Any]: 模型信息
        """
        return {
            "model_name": self.model_name,
            "model_type": get_enum_value(self.model_type),
            "provider": get_enum_value(self.provider),
            "device": str(self.device),
            "max_image_size": self.config.get("max_image_size", 512),
            "max_file_size": self.config.get("max_file_size", 10 * 1024 * 1024),
            "supported_formats": self.config.get("supported_formats", []),
            "normalize_embeddings": self.config.get("normalize_embeddings", True),
            "batch_size": self.config.get("batch_size", 16)
        }

    def _get_test_input(self) -> Tuple[str, List[str]]:
        """获取健康检查的测试输入"""
        # 创建一个简单的测试图像
        from PIL import Image, ImageDraw
        import numpy as np

        # 创建一个100x100的红色方块
        image = Image.new('RGB', (100, 100), color='red')

        # 保存为临时文件
        temp_file = os.path.join(tempfile.gettempdir(), "clip_test.jpg")
        image.save(temp_file)

        texts = ["红色", "蓝色", "绿色", "一个红色的方块"]
        return temp_file, texts

    async def benchmark_performance(self, test_images: List[Union[str, Image.Image]], test_texts: List[str], num_runs: int = 3) -> Dict[str, Any]:
        """
        性能基准测试

        Args:
            test_images: 测试图像列表
            test_texts: 测试文本列表
            num_runs: 运行次数

        Returns:
            Dict[str, Any]: 性能测试结果
        """
        try:
            logger.info(f"开始CLIP性能基准测试，图像数量: {len(test_images)}, 文本数量: {len(test_texts)}, 运行次数: {num_runs}")

            times = []
            for run in range(num_runs):
                start_time = time.time()
                await self.batch_match(test_images, test_texts)
                end_time = time.time()
                run_time = end_time - start_time
                times.append(run_time)
                logger.info(f"第{run + 1}次运行耗时: {run_time:.3f}秒")

            avg_time = np.mean(times)
            throughput = (len(test_images) * len(test_texts)) / avg_time

            results = {
                "model_name": self.model_name,
                "num_images": len(test_images),
                "num_texts": len(test_texts),
                "total_comparisons": len(test_images) * len(test_texts),
                "num_runs": num_runs,
                "times": times,
                "avg_time": float(avg_time),
                "min_time": float(np.min(times)),
                "max_time": float(np.max(times)),
                "throughput": float(throughput),  # comparisons per second
                "device": str(self.device)
            }

            logger.info(f"性能基准测试完成，平均耗时: {avg_time:.3f}秒，吞吐量: {throughput:.1f} comparisons/s")
            return results

        except Exception as e:
            error_msg = f"性能基准测试失败: {str(e)}"
            logger.error(error_msg)
            raise AIModelException(error_msg, model_name=self.model_name)

    def is_ready(self) -> bool:
        """检查CLIP模型是否已加载并就绪"""
        return True


# 创建CLIP服务实例的工厂函数
def create_clip_service(config: Dict[str, Any] = None) -> CLIPVisionService:
    """
    创建CLIP图像理解服务实例

    Args:
        config: 模型配置参数

    Returns:
        CLIPVisionService: CLIP服务实例
    """
    return CLIPVisionService(config or {})


# 全局CLIP服务实例
_clip_service = None


def get_clip_service() -> CLIPVisionService:
    """
    获取CLIP图像理解服务实例（单例模式）

    Returns:
        CLIPVisionService: CLIP服务实例
    """
    global _clip_service

    if _clip_service is None:
        _clip_service = create_clip_service()

    return _clip_service