"""
æ–‡ä»¶ç´¢å¼•ç³»ç»Ÿæµ‹è¯•è„šæœ¬

æµ‹è¯•æ–‡ä»¶ç´¢å¼•ç³»ç»Ÿçš„å„é¡¹åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- æ–‡ä»¶æ‰«æ
- å…ƒæ•°æ®æå–
- å†…å®¹è§£æ
- ç´¢å¼•æ„å»º
- å®Œæ•´çš„ç´¢å¼•æµç¨‹
"""

import os
import sys
import tempfile
import shutil
from pathlib import Path
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from app.core.config import get_settings
from app.services.file_index_service import FileIndexService

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def create_test_files(test_dir: Path) -> list[Path]:
    """åˆ›å»ºæµ‹è¯•æ–‡ä»¶"""
    test_files = []

    # åˆ›å»ºæ–‡æœ¬æ–‡æ¡£
    txt_file = test_dir / "test_document.txt"
    with open(txt_file, 'w', encoding='utf-8') as f:
        f.write("è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ã€‚\n")
        f.write("åŒ…å«ä¸­æ–‡å†…å®¹ç”¨äºæµ‹è¯•æ–‡ä»¶ç´¢å¼•ç³»ç»Ÿã€‚\n")
        f.write("This is English content for testing purposes.\n")
        f.write("æ–‡ä»¶ç´¢å¼•ç³»ç»Ÿåº”è¯¥èƒ½å¤Ÿæ­£ç¡®è§£æå’Œç´¢å¼•è¿™äº›å†…å®¹ã€‚")
    test_files.append(txt_file)

    # åˆ›å»ºMarkdownæ–‡æ¡£
    md_file = test_dir / "test_markdown.md"
    with open(md_file, 'w', encoding='utf-8') as f:
        f.write("# æµ‹è¯•Markdownæ–‡æ¡£\n\n")
        f.write("è¿™æ˜¯ä¸€ä¸ª**Markdown**æµ‹è¯•æ–‡æ¡£ã€‚\n\n")
        f.write("## åŠŸèƒ½ç‰¹ç‚¹\n")
        f.write("- æ”¯æŒä¸­æ–‡\n")
        f.write("- æ”¯æŒè‹±æ–‡\n")
        f.write("- æ”¯æŒä»£ç é«˜äº®\n\n")
        f.write("```python\n")
        f.write("def hello_world():\n")
        f.write("    print('Hello, World!')\n")
        f.write("```\n")
    test_files.append(md_file)

    # åˆ›å»ºPythonä»£ç æ–‡ä»¶
    py_file = test_dir / "test_script.py"
    with open(py_file, 'w', encoding='utf-8') as f:
        f.write("#!/usr/bin/env python3\n")
        f.write('"""\n')
        f.write("æµ‹è¯•Pythonè„šæœ¬\n")
        f.write("æ¼”ç¤ºæ–‡ä»¶ç´¢å¼•ç³»ç»Ÿçš„ä»£ç è§£æåŠŸèƒ½\n")
        f.write('"""\n\n')
        f.write("def calculate_sum(a: int, b: int) -> int:\n")
        f.write("    \"\"\"\n")
        f.write("    è®¡ç®—ä¸¤ä¸ªæ•°çš„å’Œ\n")
        f.write("    \n")
        f.write("    Args:\n")
        f.write("        a: ç¬¬ä¸€ä¸ªæ•°\n")
        f.write("        b: ç¬¬äºŒä¸ªæ•°\n")
        f.write("    \n")
        f.write("    Returns:\n")
        f.write("        int: ä¸¤æ•°ä¹‹å’Œ\n")
        f.write("    \"\"\"\n")
        f.write("    return a + b\n\n")
        f.write("if __name__ == \"__main__\":\n")
        f.write("    result = calculate_sum(10, 20)\n")
        f.write("    print(f\"è®¡ç®—ç»“æœ: {result}\")\n")
    test_files.append(py_file)

    # åˆ›å»ºHTMLæ–‡ä»¶
    html_file = test_dir / "test_webpage.html"
    with open(html_file, 'w', encoding='utf-8') as f:
        f.write("<!DOCTYPE html>\n")
        f.write("<html lang=\"zh-CN\">\n")
        f.write("<head>\n")
        f.write("    <meta charset=\"UTF-8\">\n")
        f.write("    <title>æµ‹è¯•ç½‘é¡µ</title>\n")
        f.write("</head>\n")
        f.write("<body>\n")
        f.write("    <h1>æ–‡ä»¶ç´¢å¼•ç³»ç»Ÿæµ‹è¯•</h1>\n")
        f.write("    <p>è¿™æ˜¯ä¸€ä¸ªç”¨äºæµ‹è¯•æ–‡ä»¶ç´¢å¼•ç³»ç»Ÿçš„HTMLæ–‡æ¡£ã€‚</p>\n")
        f.write("    <h2>ä¸»è¦åŠŸèƒ½</h2>\n")
        f.write("    <ul>\n")
        f.write("        <li>æ–‡ä»¶æ‰«æ</li>\n")
        f.write("        <li>å†…å®¹è§£æ</li>\n")
        f.write("        <li>ç´¢å¼•æ„å»º</li>\n")
        f.write("        <li>æœç´¢æ”¯æŒ</li>\n")
        f.write("    </ul>\n")
        f.write("</body>\n")
        f.write("</html>\n")
    test_files.append(html_file)

    # åˆ›å»ºCSSæ–‡ä»¶
    css_file = test_dir / "test_styles.css"
    with open(css_file, 'w', encoding='utf-8') as f:
        f.write("/* æµ‹è¯•CSSæ ·å¼æ–‡ä»¶ */\n")
        f.write("body {\n")
        f.write("    font-family: 'Microsoft YaHei', Arial, sans-serif;\n")
        f.write("    line-height: 1.6;\n")
        f.write("    margin: 0;\n")
        f.write("    padding: 20px;\n")
        f.write("}\n\n")
        f.write("h1 {\n")
        f.write("    color: #333;\n")
        f.write("    border-bottom: 2px solid #007acc;\n")
        f.write("}\n\n")
        f.write("/* å“åº”å¼è®¾è®¡ */\n")
        f.write("@media (max-width: 768px) {\n")
        f.write("    body {\n")
        f.write("        padding: 10px;\n")
        f.write("    }\n")
        f.write("}\n")
    test_files.append(css_file)

    logger.info(f"åˆ›å»ºäº† {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶")
    return test_files


def test_file_scanner(scanner, test_dir: Path) -> bool:
    """æµ‹è¯•æ–‡ä»¶æ‰«æåŠŸèƒ½"""
    logger.info("å¼€å§‹æµ‹è¯•æ–‡ä»¶æ‰«æåŠŸèƒ½")

    try:
        files = scanner.scan_directory(str(test_dir), recursive=True)

        if not files:
            logger.error("æ–‡ä»¶æ‰«æå¤±è´¥ï¼šæœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶")
            return False

        logger.info(f"æ–‡ä»¶æ‰«ææˆåŠŸï¼Œæ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶:")
        for file_info in files:
            logger.info(f"  - {file_info.name} ({file_info.extension}) - {file_info.size} å­—èŠ‚")

        # æ£€æŸ¥æ‰«æç»Ÿè®¡
        stats = scanner.get_stats()
        logger.info(f"æ‰«æç»Ÿè®¡: {stats}")

        return True

    except Exception as e:
        logger.error(f"æ–‡ä»¶æ‰«ææµ‹è¯•å¤±è´¥: {e}")
        return False


def test_metadata_extractor(extractor, test_files: list[Path]) -> bool:
    """æµ‹è¯•å…ƒæ•°æ®æå–åŠŸèƒ½"""
    logger.info("å¼€å§‹æµ‹è¯•å…ƒæ•°æ®æå–åŠŸèƒ½")

    try:
        for test_file in test_files:
            logger.info(f"æµ‹è¯•æ–‡ä»¶: {test_file.name}")

            metadata = extractor.extract_metadata(str(test_file))

            if 'error' in metadata:
                logger.error(f"å…ƒæ•°æ®æå–å¤±è´¥ {test_file.name}: {metadata['error']}")
                return False

            # æ£€æŸ¥åŸºæœ¬å…ƒæ•°æ®
            required_fields = ['file_name', 'file_extension', 'file_size', 'mime_type']
            for field in required_fields:
                if field not in metadata:
                    logger.error(f"ç¼ºå°‘å¿…éœ€çš„å…ƒæ•°æ®å­—æ®µ: {field}")
                    return False

            logger.info(f"  æ–‡ä»¶å: {metadata.get('file_name')}")
            logger.info(f"  æ–‡ä»¶ç±»å‹: {metadata.get('file_type')}")
            logger.info(f"  MIMEç±»å‹: {metadata.get('mime_type')}")
            logger.info(f"  æ–‡ä»¶å¤§å°: {metadata.get('file_size')} å­—èŠ‚")
            logger.info(f"  å†…å®¹å“ˆå¸Œ: {metadata.get('content_hash', 'N/A')}")

        logger.info("å…ƒæ•°æ®æå–æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        logger.error(f"å…ƒæ•°æ®æå–æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_content_parser(parser, test_files: list[Path]) -> bool:
    """æµ‹è¯•å†…å®¹è§£æåŠŸèƒ½"""
    logger.info("å¼€å§‹æµ‹è¯•å†…å®¹è§£æåŠŸèƒ½")

    try:
        for test_file in test_files:
            logger.info(f"æµ‹è¯•æ–‡ä»¶: {test_file.name}")

            parsed_content = parser.parse_content(str(test_file))

            if hasattr(parsed_content, 'error') and parsed_content.error:
                logger.error(f"å†…å®¹è§£æå¤±è´¥ {test_file.name}: {parsed_content.error}")
                return False

            logger.info(f"  æ ‡é¢˜: {parsed_content.title or 'N/A'}")
            logger.info(f"  è¯­è¨€: {parsed_content.language or 'N/A'}")
            logger.info(f"  ç¼–ç : {parsed_content.encoding or 'N/A'}")
            logger.info(f"  ç½®ä¿¡åº¦: {parsed_content.confidence:.2f}")
            logger.info(f"  å†…å®¹é•¿åº¦: {len(parsed_content.text)} å­—ç¬¦")
            logger.info(f"  å†…å®¹é¢„è§ˆ: {parsed_content.text[:100]}...")

        logger.info("å†…å®¹è§£ææµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        logger.error(f"å†…å®¹è§£ææµ‹è¯•å¤±è´¥: {e}")
        return False


def test_index_builder(builder, test_files: list[Path]) -> bool:
    """æµ‹è¯•ç´¢å¼•æ„å»ºåŠŸèƒ½"""
    logger.info("å¼€å§‹æµ‹è¯•ç´¢å¼•æ„å»ºåŠŸèƒ½")

    try:
        # å‡†å¤‡æµ‹è¯•æ–‡æ¡£æ•°æ®
        documents = []
        for i, test_file in enumerate(test_files):
            doc = {
                'id': f'test_doc_{i}',
                'title': test_file.stem,
                'content': test_file.read_text(encoding='utf-8'),
                'file_path': str(test_file),
                'file_name': test_file.name,
                'file_type': test_file.suffix[1:] if test_file.suffix else 'unknown',
                'file_size': test_file.stat().st_size,
                'modified_time': test_file.stat().st_mtime,
                'language': 'zh' if test_file.suffix in ['.txt', '.md'] else 'en',
                'tags': [test_file.suffix[1:]]
            }
            documents.append(doc)

        # æ„å»ºç´¢å¼•
        success = builder.build_indexes(documents)

        if not success:
            logger.error("ç´¢å¼•æ„å»ºå¤±è´¥")
            return False

        # è·å–ç´¢å¼•ç»Ÿè®¡
        stats = builder.get_index_stats()
        logger.info(f"ç´¢å¼•ç»Ÿè®¡: {stats}")

        # æ£€æŸ¥ç´¢å¼•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not builder.index_exists():
            logger.error("ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨")
            return False

        logger.info("ç´¢å¼•æ„å»ºæµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        logger.error(f"ç´¢å¼•æ„å»ºæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_full_index_service(index_service, test_dir: Path) -> bool:
    """æµ‹è¯•å®Œæ•´çš„æ–‡ä»¶ç´¢å¼•æœåŠ¡"""
    logger.info("å¼€å§‹æµ‹è¯•å®Œæ•´æ–‡ä»¶ç´¢å¼•æœåŠ¡")

    try:
        # æµ‹è¯•å®Œæ•´ç´¢å¼•æ„å»º
        logger.info("æµ‹è¯•å®Œæ•´ç´¢å¼•æ„å»º...")
        result = index_service.build_full_index(
            scan_paths=[str(test_dir)],
            progress_callback=lambda msg, progress: logger.info(f"è¿›åº¦: {msg} - {progress:.1f}%")
        )

        if not result['success']:
            logger.error(f"å®Œæ•´ç´¢å¼•æ„å»ºå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return False

        logger.info(f"å®Œæ•´ç´¢å¼•æ„å»ºæˆåŠŸ:")
        logger.info(f"  å‘ç°æ–‡ä»¶: {result.get('total_files_found', 0)}")
        logger.info(f"  ç´¢å¼•æ–‡æ¡£: {result.get('documents_indexed', 0)}")
        logger.info(f"  å¤±è´¥æ–‡ä»¶: {result.get('failed_files', 0)}")
        logger.info(f"  è€—æ—¶: {result.get('duration_seconds', 0):.2f} ç§’")

        # æµ‹è¯•ç´¢å¼•çŠ¶æ€
        logger.info("æµ‹è¯•ç´¢å¼•çŠ¶æ€æŸ¥è¯¢...")
        status = index_service.get_index_status()
        logger.info(f"ç´¢å¼•çŠ¶æ€: {status}")

        # æµ‹è¯•æ”¯æŒçš„æ ¼å¼
        logger.info("æµ‹è¯•æ”¯æŒçš„æ ¼å¼...")
        formats = index_service.get_supported_formats()
        logger.info(f"æ”¯æŒçš„æ ¼å¼æ•°é‡: æ‰«æå™¨ {len(formats.get('scanner_formats', []))}, "
                   f"è§£æå™¨ {len(formats.get('parser_formats', []))}")

        logger.info("å®Œæ•´æ–‡ä»¶ç´¢å¼•æœåŠ¡æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        logger.error(f"å®Œæ•´æ–‡ä»¶ç´¢å¼•æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("å¼€å§‹æ–‡ä»¶ç´¢å¼•ç³»ç»Ÿæµ‹è¯•")

    # åˆ›å»ºä¸´æ—¶æµ‹è¯•ç›®å½•
    with tempfile.TemporaryDirectory() as temp_dir:
        test_dir = Path(temp_dir)
        logger.info(f"åˆ›å»ºä¸´æ—¶æµ‹è¯•ç›®å½•: {test_dir}")

        try:
            # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
            test_files = create_test_files(test_dir)

            # è·å–è®¾ç½®
            settings = get_settings()

            # åˆ›å»ºæµ‹è¯•æ•°æ®ç›®å½•
            test_data_root = test_dir / "index_data"
            test_data_root.mkdir(exist_ok=True)

            # è·å–ç´¢å¼•è·¯å¾„
            faiss_path = str(test_data_root / "indexes" / "faiss" / "test_index.faiss")
            whoosh_path = str(test_data_root / "indexes" / "whoosh")

            # åˆå§‹åŒ–æ–‡ä»¶ç´¢å¼•æœåŠ¡
            logger.info("åˆå§‹åŒ–æ–‡ä»¶ç´¢å¼•æœåŠ¡...")
            index_service = FileIndexService(
                data_root=str(test_data_root),
                faiss_index_path=faiss_path,
                whoosh_index_path=whoosh_path,
                use_chinese_analyzer=True,
                scanner_config={
                    'max_workers': 2,
                    'max_file_size': 10 * 1024 * 1024,  # 10MB
                    'supported_extensions': {'.txt', '.md', '.py', '.html', '.css', '.js'}
                },
                parser_config={
                    'max_content_length': 100 * 1024  # 100KB
                }
            )

            # è·å–å­æœåŠ¡è¿›è¡Œå•ç‹¬æµ‹è¯•
            scanner = index_service.scanner
            extractor = index_service.metadata_extractor
            parser = index_service.content_parser
            builder = index_service.index_builder

            # è¿è¡Œå„é¡¹æµ‹è¯•
            test_results = []

            # 1. æµ‹è¯•æ–‡ä»¶æ‰«æ
            test_results.append(("æ–‡ä»¶æ‰«æ", test_file_scanner(scanner, test_dir)))

            # 2. æµ‹è¯•å…ƒæ•°æ®æå–
            test_results.append(("å…ƒæ•°æ®æå–", test_metadata_extractor(extractor, test_files)))

            # 3. æµ‹è¯•å†…å®¹è§£æ
            test_results.append(("å†…å®¹è§£æ", test_content_parser(parser, test_files)))

            # 4. æµ‹è¯•ç´¢å¼•æ„å»º
            test_results.append(("ç´¢å¼•æ„å»º", test_index_builder(builder, test_files)))

            # 5. æµ‹è¯•å®Œæ•´æœåŠ¡
            test_results.append(("å®Œæ•´ç´¢å¼•æœåŠ¡", test_full_index_service(index_service, test_dir)))

            # è¾“å‡ºæµ‹è¯•ç»“æœ
            logger.info("\n" + "="*50)
            logger.info("æµ‹è¯•ç»“æœæ±‡æ€»:")
            logger.info("="*50)

            all_passed = True
            for test_name, result in test_results:
                status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
                logger.info(f"{test_name:20} {status}")
                if not result:
                    all_passed = False

            logger.info("="*50)

            if all_passed:
                logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ–‡ä»¶ç´¢å¼•ç³»ç»Ÿå·¥ä½œæ­£å¸¸ã€‚")
                return True
            else:
                logger.error("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½ã€‚")
                return False

        except Exception as e:
            logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)